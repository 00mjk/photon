From a663a860819287e041c3de672aad1d8543098ecc Mon Sep 17 00:00:00 2001
From: Jonathon Jongsma <jjongsma@redhat.com>
Date: Thu, 5 Dec 2019 10:08:52 -0600
Subject: [PATCH] qemu: don't hold both jobs for suspend
We have to assume that the guest agent may be malicious so we don't want
to allow any agent queries to block any other libvirt API. By holding a
monitor job while we're querying the agent, we open ourselves up to a
DoS.
So split the function up a bit to only hold the monitor job while
querying qemu for whether the domain supports suspend. Then acquire only
an agent job while issuing the agent suspend command.

Signed-off-by: Jonathon Jongsma <jjongsma@redhat.com>
Signed-off-by: Michal Privoznik <mprivozn@redhat.com>
Reviewed-by: Michal Privoznik <mprivozn@redhat.com>

Re-created patch for libvirt-3.2.0 version by referring actual upstream patch.
Signed-off-by: Harinadh Dommaraju <hdommaraju@vmware.com>
Reviewed-by: Keerthana Kalyanasundaram <keerthanak@vmware.com>
---
--- a/src/qemu/qemu_driver.c	2020-04-06 09:11:31.926406581 +0530
+++ b/src/qemu/qemu_driver.c	2020-04-08 02:31:40.716154076 +0530
@@ -17990,6 +17990,69 @@ qemuDomainGetCPUStats(virDomainPtr domai
     return ret;
 }
 
+
+static int
+qemuDomainProbeQMPCurrentMachine(virQEMUDriverPtr driver,virDomainObjPtr vm,bool *wakeupSupported)
+{
+    qemuDomainObjPrivatePtr priv = vm->privateData;
+    qemuMonitorCurrentMachineInfo info = { 0 };
+    int rv;
+
+    qemuDomainObjEnterMonitor(driver, vm);
+    rv = qemuMonitorGetCurrentMachineInfo(priv->mon, &info);
+    if (qemuDomainObjExitMonitor(driver, vm) < 0 || rv < 0)
+        return -1;
+
+    *wakeupSupported = info.wakeupSuspendSupport;
+    return 0;
+}
+
+/* returns -1 on error, or if query is not supported, 0 if query was
+ * successful
+ */
+static int
+qemuDomainQueryWakeupSuspendSupport(virQEMUDriverPtr driver,virDomainObjPtr vm,bool *wakeupSupported)
+{   
+    qemuDomainObjPrivatePtr priv = vm->privateData;
+    int ret = -1;
+                                
+    if (!virQEMUCapsGet(priv->qemuCaps, QEMU_CAPS_QUERY_CURRENT_MACHINE))
+        return -1;
+    if (qemuDomainObjBeginJob(driver, vm, QEMU_JOB_MODIFY) < 0)
+        return -1;
+    if ((ret = virDomainObjCheckActive(vm)) < 0)
+        goto endjob;
+    ret = qemuDomainProbeQMPCurrentMachine(driver, vm, wakeupSupported);                            
+endjob:
+    qemuDomainObjEndJob(driver, vm);
+    return ret;
+}
+
+static int
+qemuDomainPMSuspendAgent(virQEMUDriverPtr driver,virDomainObjPtr vm,unsigned int target)
+{   
+    qemuAgentPtr agent;
+    int ret = -1;
+                            
+    if (qemuDomainObjBeginAgentJob(driver, vm, QEMU_JOB_MODIFY) < 0)
+        return -1;
+                                    
+    if ((ret = virDomainObjCheckActive(vm)) < 0)
+        goto endjob;
+                            
+    if (!qemuDomainAgentAvailable(vm, true))
+        goto endjob;
+                            
+    agent = qemuDomainObjEnterAgent(vm);
+    ret = qemuAgentSuspend(agent, target);
+    qemuDomainObjExitAgent(vm, agent);
+                                        
+endjob:
+    qemuDomainObjEndAgentJob(vm);
+    return ret;
+}
+
+
 static int
 qemuDomainPMSuspendForDuration(virDomainPtr dom,
                                unsigned int target,
@@ -17997,10 +18060,9 @@ qemuDomainPMSuspendForDuration(virDomain
                                unsigned int flags)
 {
     virQEMUDriverPtr driver = dom->conn->privateData;
-    qemuDomainObjPrivatePtr priv;
     virDomainObjPtr vm;
-    qemuAgentPtr agent;
     int ret = -1;
+    bool wakeupSupported;
 
     virCheckFlags(0, -1);
 
@@ -18022,28 +18084,23 @@ qemuDomainPMSuspendForDuration(virDomain
     if (!(vm = qemuDomObjFromDomain(dom)))
         goto cleanup;
 
-    priv = vm->privateData;
-
     if (virDomainPMSuspendForDurationEnsureACL(dom->conn, vm->def) < 0)
         goto cleanup;
-
-    if (qemuDomainObjBeginJob(driver, vm, QEMU_JOB_MODIFY) < 0)
-        goto cleanup;
-
-    if (!virDomainObjIsActive(vm)) {
-        virReportError(VIR_ERR_OPERATION_INVALID,
-                       "%s", _("domain is not running"));
-        goto endjob;
+     
+    /*
+     * The case we want to handle here is when QEMU has the API (i.e
+     * QEMU_CAPS_QUERY_CURRENT_MACHINE is set). Otherwise, do not interfere
+     * with the suspend process. This means that existing running domains,
+     * that don't know about this cap, will keep their old behavior of
+     * suspending 'in the dark'.
+     */
+    if (qemuDomainQueryWakeupSuspendSupport(driver, vm, &wakeupSupported) == 0) {
+        if (!wakeupSupported) {
+            virReportError(VIR_ERR_OPERATION_UNSUPPORTED, "%s",_("Domain does not have suspend support"));
+                goto cleanup;
+        }
     }
 
-    if (!virQEMUCapsGet(priv->qemuCaps, QEMU_CAPS_WAKEUP) &&
-        (target == VIR_NODE_SUSPEND_TARGET_MEM ||
-         target == VIR_NODE_SUSPEND_TARGET_HYBRID)) {
-        virReportError(VIR_ERR_ARGUMENT_UNSUPPORTED, "%s",
-                       _("Unable to suspend domain due to "
-                         "missing system_wakeup monitor command"));
-        goto endjob;
-    }
 
     if (vm->def->pm.s3 || vm->def->pm.s4) {
         if (vm->def->pm.s3 == VIR_TRISTATE_BOOL_NO &&
@@ -18051,26 +18108,18 @@ qemuDomainPMSuspendForDuration(virDomain
              target == VIR_NODE_SUSPEND_TARGET_HYBRID)) {
             virReportError(VIR_ERR_INTERNAL_ERROR, "%s",
                            _("S3 state is disabled for this domain"));
-            goto endjob;
+            goto cleanup;
         }
 
         if (vm->def->pm.s4 == VIR_TRISTATE_BOOL_NO &&
             target == VIR_NODE_SUSPEND_TARGET_DISK) {
             virReportError(VIR_ERR_INTERNAL_ERROR, "%s",
                            _("S4 state is disabled for this domain"));
-            goto endjob;
+            goto cleanup;
         }
     }
 
-    if (!qemuDomainAgentAvailable(vm, true))
-        goto endjob;
-
-    agent = qemuDomainObjEnterAgent(vm);
-    ret = qemuAgentSuspend(agent, target);
-    qemuDomainObjExitAgent(vm, agent);
-
- endjob:
-    qemuDomainObjEndJob(driver, vm);
+    ret = qemuDomainPMSuspendAgent(driver, vm, target);
 
  cleanup:
     virDomainObjEndAPI(&vm);
--- a/src/qemu/qemu_capabilities.c	2020-04-06 09:11:49.910405826 +0530
+++ b/src/qemu/qemu_capabilities.c	2020-04-08 01:36:48.388292410 +0530
@@ -364,6 +364,7 @@ VIR_ENUM_IMPL(virQEMUCaps, QEMU_CAPS_LAS
               "query-cpu-definitions", /* 250 */
               "block-write-threshold",
               "query-named-block-nodes",
+	      "query-current-machine",
     );
 
 
@@ -1486,7 +1487,8 @@ struct virQEMUCapsStringFlags virQEMUCap
     { "query-qmp-schema", QEMU_CAPS_QUERY_QMP_SCHEMA },
     { "query-cpu-model-expansion", QEMU_CAPS_QUERY_CPU_MODEL_EXPANSION},
     { "query-cpu-definitions", QEMU_CAPS_QUERY_CPU_DEFINITIONS},
-    { "query-named-block-nodes", QEMU_CAPS_QUERY_NAMED_BLOCK_NODES}
+    { "query-named-block-nodes", QEMU_CAPS_QUERY_NAMED_BLOCK_NODES},
+    { "query-current-machine", QEMU_CAPS_QUERY_CURRENT_MACHINE },
 };
 
 struct virQEMUCapsStringFlags virQEMUCapsMigration[] = {
--- a/src/qemu/qemu_capabilities.h	2020-04-06 09:11:53.990405654 +0530
+++ b/src/qemu/qemu_capabilities.h	2020-04-08 01:38:38.176287797 +0530
@@ -401,6 +401,7 @@ typedef enum {
     QEMU_CAPS_QUERY_CPU_DEFINITIONS, /* qmp query-cpu-definitions */
     QEMU_CAPS_BLOCK_WRITE_THRESHOLD, /* BLOCK_WRITE_THRESHOLD event */
     QEMU_CAPS_QUERY_NAMED_BLOCK_NODES, /* qmp query-named-block-nodes */
+    QEMU_CAPS_QUERY_CURRENT_MACHINE, /* query-current-machine command */
 
     QEMU_CAPS_LAST /* this must always be the last item */
 } virQEMUCapsFlags;
--- a/src/qemu/qemu_monitor.c	2020-04-06 09:12:06.546405127 +0530
+++ b/src/qemu/qemu_monitor.c	2020-04-08 01:39:44.736285000 +0530
@@ -4280,3 +4280,10 @@ qemuMonitorEventPanicInfoFree(qemuMonito
 
     VIR_FREE(info);
 }
+
+int qemuMonitorGetCurrentMachineInfo(qemuMonitorPtr mon,
+		qemuMonitorCurrentMachineInfoPtr info)
+{
+	 QEMU_CHECK_MONITOR(mon);
+	 return qemuMonitorJSONGetCurrentMachineInfo(mon, info);
+}
--- a/src/qemu/qemu_monitor.h	2020-04-06 09:12:10.886404944 +0530
+++ b/src/qemu/qemu_monitor.h	2020-04-08 01:40:30.148283092 +0530
@@ -1119,4 +1119,12 @@ int qemuMonitorSetBlockThreshold(qemuMon
 
 virJSONValuePtr qemuMonitorQueryNamedBlockNodes(qemuMonitorPtr mon);
 
+typedef struct  _qemuMonitorCurrentMachineInfo qemuMonitorCurrentMachineInfo;
+typedef qemuMonitorCurrentMachineInfo *qemuMonitorCurrentMachineInfoPtr;
+struct _qemuMonitorCurrentMachineInfo {
+	bool wakeupSuspendSupport;
+};
+
+int qemuMonitorGetCurrentMachineInfo(qemuMonitorPtr mon,qemuMonitorCurrentMachineInfoPtr info);
+
 #endif /* QEMU_MONITOR_H */
--- a/src/qemu/qemu_monitor_json.c	2020-04-06 09:12:28.442404207 +0530
+++ b/src/qemu/qemu_monitor_json.c	2020-04-08 01:41:11.976281335 +0530
@@ -7644,3 +7644,49 @@ qemuMonitorJSONQueryNamedBlockNodes(qemu
 
     return ret;
 }
+
+static int
+qemuMonitorJSONExtractCurrentMachineInfo(virJSONValuePtr reply,
+		qemuMonitorCurrentMachineInfoPtr info)
+{
+    virJSONValuePtr data;
+
+    data = virJSONValueObjectGetObject(reply, "return");
+    if (!data)
+        goto malformed;
+
+    if (virJSONValueObjectGetBoolean(data, "wakeup-suspend-support",&info->wakeupSuspendSupport) < 0)
+        goto malformed;
+
+    return 0;
+
+    malformed:
+        virReportError(VIR_ERR_INTERNAL_ERROR, "%s",_("malformed qemu-current-machine reply"));
+        return -1;
+}
+
+
+int
+qemuMonitorJSONGetCurrentMachineInfo(qemuMonitorPtr mon,
+		qemuMonitorCurrentMachineInfoPtr info)
+{
+    int ret = -1;
+    virJSONValuePtr cmd;
+    virJSONValuePtr reply = NULL;
+
+    if (!(cmd = qemuMonitorJSONMakeCommand("query-current-machine",NULL)))
+        return -1;
+
+    if (qemuMonitorJSONCommand(mon, cmd, &reply) < 0)
+        goto cleanup;
+
+    if (qemuMonitorJSONCheckReply(cmd, reply, VIR_JSON_TYPE_OBJECT) < 0)
+        goto cleanup;
+
+    ret = qemuMonitorJSONExtractCurrentMachineInfo(reply, info);
+
+    cleanup:
+        virJSONValueFree(cmd);
+        virJSONValueFree(reply);
+        return ret;
+}
--- a/src/qemu/qemu_monitor_json.h	2020-04-06 09:12:33.082404012 +0530
+++ b/src/qemu/qemu_monitor_json.h	2020-04-08 01:41:21.944280916 +0530
@@ -521,5 +521,6 @@ int qemuMonitorJSONSetBlockThreshold(qem
 
 virJSONValuePtr qemuMonitorJSONQueryNamedBlockNodes(qemuMonitorPtr mon)
     ATTRIBUTE_NONNULL(1);
-
+int qemuMonitorJSONGetCurrentMachineInfo(qemuMonitorPtr mon,qemuMonitorCurrentMachineInfoPtr info)
+    ATTRIBUTE_NONNULL(1) ATTRIBUTE_NONNULL(2);
 #endif /* QEMU_MONITOR_JSON_H */
